import OpenAI from 'openai';
import { AIService, AIResponse, GenerateConfig } from '../interfaces/ai-service.interface';

/**
 * OpenAI æœå‹™å¯¦ä½œ
 * ä½¿ç”¨ OpenAI API ç”Ÿæˆå…§å®¹
 */
export class OpenAIService implements AIService {
    private apiKey: string;
    private model: string;

    /**
     * å»ºç«‹ OpenAI æœå‹™å¯¦ä¾‹
     * @param apiKey - OpenAI API é‡‘é‘°
     * @param model - æ¨¡å‹åç¨±ï¼Œé è¨­ç‚º 'gpt-4o'
     * @throws {Error} ç•¶ apiKey æœªæä¾›æ™‚æ‹‹å‡ºéŒ¯èª¤
     */
    constructor(apiKey: string, model: string = 'gpt-4o') {
        if (!apiKey || apiKey.trim() === '') {
            throw new Error('â›” API key is required for OpenAI service');
        }

        if (!model || model.trim() === '') {
            throw new Error('â›” Model name is required for OpenAI service');
        }

        this.apiKey = apiKey;
        this.model = model;
    }

    /**
     * ç”Ÿæˆè©•è«–å…§å®¹
     * @param systemInstruction - ç³»çµ±æŒ‡ä»¤
     * @param prompt - æç¤ºè©
     * @param config - ç”Ÿæˆè¨­å®š (é¸ç”¨)
     * @returns AI æœå‹™å›æ‡‰
     */
    public async generateComment(
        systemInstruction: string,
        prompt: string,
        config?: GenerateConfig
    ): Promise<AIResponse> {
        console.log('ğŸš© Generating response using OpenAI...');

        try {
            // å»ºç«‹ OpenAI å®¢æˆ¶ç«¯
            const client = new OpenAI({ apiKey: this.apiKey });

            // æº–å‚™è¨Šæ¯é™£åˆ—
            const messages: OpenAI.Chat.Completions.ChatCompletionMessageParam[] = [];
            
            if (systemInstruction && systemInstruction.trim() !== '') {
                messages.push({ role: 'system', content: systemInstruction });
            }
            
            messages.push({ role: 'user', content: prompt });

            // æº–å‚™è«‹æ±‚åƒæ•¸
            const requestOptions: OpenAI.Chat.Completions.ChatCompletionCreateParamsNonStreaming = {
                model: this.model,
                messages: messages
            };

            // è‹¥æœ‰æä¾›è¨­å®šï¼Œå‰‡åŠ å…¥ç”Ÿæˆè¨­å®š
            if (config) {
                if (config.temperature !== undefined) {
                    requestOptions.temperature = config.temperature;
                }
                if (config.maxOutputTokens !== undefined) {
                    requestOptions.max_completion_tokens = config.maxOutputTokens;
                }
            }

            const response = await client.chat.completions.create(requestOptions);

            // å–å¾—å›æ‡‰å…§å®¹
            const content = response.choices?.[0]?.message?.content || 'No response generated';
            console.log('âœ… Response generated successfully');
            return { content };

        } catch (error: any) {
            const message = JSON.stringify(error.response?.data || error.message);
            throw new Error('â›” OpenAI service error: ' + message);
        }
    }
}
